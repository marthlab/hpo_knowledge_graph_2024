{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from pyhpo import Ontology\n",
    "import itertools\n",
    "Ontology()\n",
    "\n",
    "import fastobo \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor #For multi threading\n",
    "from gensim.models import Word2Vec #For Node2Vec\n",
    "from sklearn.metrics.pairwise import cosine_distances #measure cosine distance\n",
    "import patient_matching #to get patient matching functions\n",
    "\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "#use block below to instal new packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Files and Diagnosis File Processing\n",
    "\n",
    "Import files needed to add String DB associated genes to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import files for gene matching\n",
    "gene_data = pd.read_table('./data_files/9606.protein.info.v12.0.txt') #Import String Protein names and IDs\n",
    "gene_associations = pd.read_table('./data_files/9606.protein.links.detailed.v12.0.txt',delimiter=' ') #Import gene associations\n",
    "patient_data = pd.read_csv('./data_files/753_UDNDx_Patients_8.26.24.csv') #import patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block is building gene associations based on String db\n",
    "#Isolate protein id and preferred names\n",
    "select_data = gene_data[['#string_protein_id','preferred_name']]\n",
    "#We will convert this to a dictionary for later ease\n",
    "gene_dict = dict(zip(gene_data['#string_protein_id'], gene_data['preferred_name'])) # gene_dict is the gene dictionary of interest\n",
    "\n",
    "#Filter high confidence associations\n",
    "high_con_associations = gene_associations.loc[gene_associations['combined_score'] >= 700] #Set confidence score to select interactions of interest\n",
    "#filter data frame\n",
    "high_con_associations = high_con_associations[['protein1','protein2','combined_score']]\n",
    "high_con_associations['protein1'] = high_con_associations['protein1'].map(gene_dict)\n",
    "high_con_associations['protein2'] = high_con_associations['protein2'].map(gene_dict)\n",
    "\n",
    "association_data = []\n",
    "high_con_associations = list(high_con_associations.itertuples(index=False, name=None)) #convert high con associations into a list of tuples\n",
    "i = 0 #initialize i as the index in the table\n",
    "j = 0 #initialize j as the index in the output dataframe\n",
    "while i < len(high_con_associations) :\n",
    "    j = j +1 \n",
    "    protein = high_con_associations[i][0] #0 is index of protein 1\n",
    "    protein_list =[]\n",
    "    num_protein = 0\n",
    "    while protein == high_con_associations[i][0]:\n",
    "        num_protein = num_protein + 1 \n",
    "        associated_protein = (high_con_associations[i][1],high_con_associations[i][2])\n",
    "        protein_list.append(associated_protein)\n",
    "        i = i + 1 \n",
    "        if i == len(high_con_associations):\n",
    "            break\n",
    "    association_data.append([protein ,num_protein, protein_list])\n",
    "association_data = pd.DataFrame(association_data, columns=['Gene', '# Of Associated Genes', 'Associated Genes'])\n",
    "\n",
    "#For now we will stick to only one gene diagnosis, this loop takes about 0.1 seconds to run and is not a big time problem\n",
    "#patient_data.rename(columns={'Genes' : 'Gene 1'})\n",
    "for i in range(len(patient_data)):\n",
    "    gene = patient_data.loc[i]['Genes']\n",
    "    if ',' in gene or ';' in gene:\n",
    "        #print(gene)\n",
    "        patient_data = patient_data.drop([i])\n",
    "\n",
    "patient_data = patient_data.rename(columns={'Genes' : \"Gene\"})\n",
    "filtered_patient_data = pd.merge(patient_data, association_data, on='Gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_file = filtered_patient_data #The rest of the script uses diagnosis file \n",
    "#HPO terms are saved as a string, convert to a list\n",
    "diagnosis_file['Terms'] = diagnosis_file['Terms'].apply(lambda x: x.split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Similarity table\n",
    "similarity_table = pd.read_csv('./data_files/753_Dx_Individuals_jaccardIC_omim_5.3.24_similarity_table.csv')\n",
    "similarity_table = similarity_table.rename(columns={'Unnamed: 0' : 'Patient ID/Patient ID'})\n",
    "similarity_table = similarity_table.set_index('Patient ID/Patient ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a list of patients to loop through\n",
    "patient_list = diagnosis_file['ID'].tolist()\n",
    "\n",
    "#Drop patients from the similairty table that we are not looking at in the diagnosis file\n",
    "for i in similarity_table.index:\n",
    "    if i not in patient_list:\n",
    "        similarity_table = similarity_table.drop(columns=i).drop([i])\n",
    "\n",
    "phenotypic_similarity = similarity_table\n",
    "phenotypic_similarity.index.name = 'ID'\n",
    "\n",
    "genetic_data = diagnosis_file\n",
    "genetic_data = genetic_data.set_index('ID')\n",
    "\n",
    "#We need a matrix wherein we have patient ID in one coloumn and a matrix of genes that are associated with the patient\n",
    "#Remove confidence scores in associated genes coloumn\n",
    "diagnosis_file['Associated Genes'] = diagnosis_file['Associated Genes'].apply(lambda lst: [tup[0] for tup in lst])\n",
    "genetic_data = diagnosis_file[['ID','Associated Genes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View final diagnosis file\n",
    "diagnosis_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import HPO-Gene associations\n",
    "HPO_gene_data = pd.read_table('./data_files/genes_to_phenotype.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Network X Graph\n",
    "We will make a networkX graph first, add all nodes and edges and then convert it to a stellar graph \n",
    "Stellar graph does not let us add things one by one and I am a noob and would like to add things one by one for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will set up a new graph\n",
    "\n",
    "\n",
    "#We need to add the HPO term hierarchy in the model and will do so with code from Isabelle\n",
    "pato = fastobo.load('./data_files/hp.obo')\n",
    "\n",
    "#We will make a directed graph or undirected graph depending on what is easeir to integrate\n",
    "knowledge_graph = nx.MultiGraph()\n",
    "\n",
    "\n",
    "terms = []\n",
    "for frame in pato:\n",
    "    if isinstance(frame, fastobo.term.TermFrame):\n",
    "        knowledge_graph.add_node(str(frame.id), node_type='HPO Term')\n",
    "        terms.append(str(frame.id))\n",
    "        for clause in frame:\n",
    "            if isinstance(clause, fastobo.term.IsAClause):\n",
    "                knowledge_graph.add_edge(str(frame.id), str(clause.term))\n",
    "\n",
    "#Get info\n",
    "print(nx.info(knowledge_graph))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert high con associations into a dataframe\n",
    "high_con_associations = pd.DataFrame(high_con_associations, columns=['Protein 1','Protein 2', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all high confidence gene interactions to the graph n\n",
    "\n",
    "#Add all genes in the string db\n",
    "genes = gene_data[['preferred_name']]\n",
    "genes = genes['preferred_name'].astype(str).str.strip() #reformat strings so that they are all correctly recognized as nodes\n",
    "knowledge_graph.add_nodes_from(genes, node_type = 'Genes')\n",
    "\n",
    "#Add all high con associations\n",
    "interactions_list = list(high_con_associations[['Protein 1', 'Protein 2']].itertuples(index=False, name=None))\n",
    "\n",
    "knowledge_graph.add_edges_from(interactions_list)\n",
    "\n",
    "#Get info\n",
    "print(nx.info(knowledge_graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to add genes that HPO terms are connected to but are not present in GeneDb\n",
    "additional_genes = set(HPO_gene_data['gene_symbol'].to_list())\n",
    "additional_genes = list(set(additional_genes) - set(genes))\n",
    "print(len(additional_genes), 'genes not in string db')\n",
    "\n",
    "knowledge_graph.add_nodes_from(additional_genes, node_type = 'Genes' )\n",
    "\n",
    "#Get info\n",
    "print(nx.info(knowledge_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now need to link HPO terms to genes\n",
    "HPO_interactions = list(HPO_gene_data[['gene_symbol','hpo_id']].itertuples(index=False, name=None))\n",
    "knowledge_graph.add_edges_from(HPO_interactions)\n",
    "\n",
    "#Get info\n",
    "print(nx.info(knowledge_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add patient nodes and add edges for each patient to its HPO terms\n",
    "\n",
    "knowledge_graph.add_nodes_from(diagnosis_file['ID'].to_list(), node_type='Patient')\n",
    "\n",
    "#Loop through each patient to add thier edges\n",
    "for patient in diagnosis_file['ID']:\n",
    "    term_list = diagnosis_file[diagnosis_file['ID']== patient]['Terms']\n",
    "    term_list = list(itertools.chain.from_iterable(term_list))\n",
    "\n",
    "    for term in term_list:\n",
    "        term = term.strip()\n",
    "        knowledge_graph.add_edge(patient,term)\n",
    "    \n",
    "#Get info\n",
    "print(nx.info(knowledge_graph))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert networkX graph to a stellar graph and perform random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will have to convert the diagnosed genes into a matrix to feed it into the graph\n",
    "#This will be a similar approach to how we made a gene matrix for associated genes previously\n",
    "\n",
    "stellar_knowledge_graph = StellarGraph.from_networkx(knowledge_graph, node_type_attr='node_type')\n",
    "\n",
    "print(stellar_knowledge_graph.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will multiprocess the random walks, they take about 90 minutes on a single thread\n",
    "\n",
    "\n",
    "rw = BiasedRandomWalk(stellar_knowledge_graph)\n",
    "\n",
    "# Define a function that will run walks on a chunk of nodes\n",
    "def run_walks_on_chunk(nodes_chunk):\n",
    "    return rw.run(nodes=nodes_chunk, n=10, length=5, p=1, q=1)\n",
    "\n",
    "# Get the list of all nodes in the graph\n",
    "all_nodes = list(stellar_knowledge_graph.nodes())\n",
    "\n",
    "# Set the number of workers (threads) you want\n",
    "num_workers = 10\n",
    "\n",
    "# Split the list of nodes into chunks, one for each worker\n",
    "node_chunks = [all_nodes[i::num_workers] for i in range(num_workers)]\n",
    "\n",
    "# Run the walks in parallel using ThreadPoolExecutor\n",
    "with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "    # Map the node chunks to the walk function\n",
    "    walks_results = list(executor.map(run_walks_on_chunk, node_chunks))\n",
    "\n",
    "# Combine the results from all threads\n",
    "walks = [walk for result in walks_results for walk in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "model = Word2Vec(str_walks, size=128, window=5, min_count=0, sg=1, workers=10, iter=1) #sh=0 might be more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve node embeddings and corresponding subjects\n",
    "node_ids = model.wv.index2word  # list of node IDs\n",
    "node_embeddings = (\n",
    "    model.wv.vectors\n",
    ") \n",
    "\n",
    "# Apply t-SNE transformation on node embeddings\n",
    "tsne = TSNE(n_components=2)\n",
    "node_embeddings_2d = tsne.fit_transform(node_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types = [stellar_knowledge_graph.node_type(node) for node in node_ids]\n",
    "\n",
    "nodes_data = pd.DataFrame({'Node':node_ids, 'node_type':node_types,'Position 1':node_embeddings_2d[:,0], 'Position 2':node_embeddings_2d[:,1]})\n",
    "nodes_data = nodes_data.set_index('Node')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_data[nodes_data['node_type']== 'Genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save embeddings\n",
    "#np.save('node_embeddings.npy', node_embeddings)\n",
    "#Save node data TSNE points as a dataframe\n",
    "#nodes_data.to_csv('nodes_data_tsne.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import embeddings and TSNE points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_embeddings = np.load('node_embeddings.npy')\n",
    "#nodes_data = pd.read_csv('nodes_data_tsne.csv')\n",
    "\n",
    "#node_embeddings_2d = nodes_data[['Position 1', 'Position 2']].to_numpy()\n",
    "#node_ids = nodes_data['Node']\n",
    "#node_types = [stellar_knowledge_graph.node_type(node) for node in node_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TSNE Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a TSNE Graph\n",
    "alpha = 0.3 #Determines transparecy of points\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RFC 1 Patinet HPO Terms\n",
    "alpha = 0.3\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "#Grab a patients HPO terms and visualize them on the scatter plot\n",
    "diagnosis_file\n",
    "RFC1_patients = diagnosis_file[diagnosis_file['Gene']=='RFC1']\n",
    "RFC1_patients = RFC1_patients['Terms']\n",
    "RFC1_patients = RFC1_patients.apply(lambda terms: [term.strip() for term in terms])\n",
    "\n",
    "rows_to_plot = nodes_data.loc[RFC1_patients[1]]\n",
    "rows_to_plot\n",
    "plt.scatter(rows_to_plot['Position 1'], rows_to_plot['Position 2'], color='red')\n",
    "\n",
    "rows_to_plot_2 = nodes_data.loc[RFC1_patients[2]]\n",
    "plt.scatter(rows_to_plot_2['Position 1'], rows_to_plot_2['Position 2'], color='green')\n",
    "\n",
    "rows_to_plot_3 = nodes_data.loc[RFC1_patients[3]]\n",
    "plt.scatter(rows_to_plot_3['Position 1'], rows_to_plot_3['Position 2'], color='purple')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RFC1 Patients\n",
    "alpha = 0.3\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "RFC1_patients = diagnosis_file[diagnosis_file['Gene']=='RFC1']\n",
    "RFC1_patients = RFC1_patients['ID']\n",
    "RFC1_patients\n",
    "\n",
    "patient_1 = nodes_data.loc[RFC1_patients[1]]\n",
    "plt.scatter(patient_1['Position 1'], patient_1['Position 2'], color='red')\n",
    "\n",
    "patient_2 = nodes_data.loc[RFC1_patients[2]]\n",
    "plt.scatter(patient_2['Position 1'], patient_2['Position 2'], color='orange')\n",
    "\n",
    "patient_3 = nodes_data.loc[RFC1_patients[3]]\n",
    "plt.scatter(patient_3['Position 1'], patient_3['Position 2'], color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot All Patinet Nodes\n",
    "alpha = 0.3\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "#Try plotting only patient nodes\n",
    "patient_nodes = nodes_data[nodes_data['node_type']=='Patient']\n",
    "patient_nodes\n",
    "plt.scatter(patient_nodes['Position 1'], patient_nodes['Position 2'], color='red', alpha = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Patinet nodes for all genes that have morr than 3 patients with the same gene diagnosis\n",
    "\n",
    "gene_diag = diagnosis_file[['ID','Gene']]\n",
    "gene_diag = gene_diag.set_index('ID')\n",
    "patient_nodes = pd.merge(patient_nodes,gene_diag, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "patient_nodes = patient_nodes.groupby('Gene').filter(lambda x: len(x) > 3)\n",
    "\n",
    "# Get unique diagnoses\n",
    "unique_diagnoses = patient_nodes['Gene'].unique()\n",
    "\n",
    "# Create a color map with a number of colors equal to the number of unique diagnoses\n",
    "colors = plt.cm.inferno_r(np.linspace(0, 1, len(unique_diagnoses)))\n",
    "\n",
    "# Create a mapping from diagnosis to color\n",
    "diagnosis_color_map = dict(zip(unique_diagnoses, colors))\n",
    "\n",
    "# draw the points\n",
    "alpha = 0.3\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "\n",
    "# Plot each diagnosis with its corresponding color\n",
    "for diagnosis in unique_diagnoses:\n",
    "    subset = patient_nodes[patient_nodes['Gene'] == diagnosis]\n",
    "    plt.scatter(subset['Position 1'], subset['Position 2'], label=diagnosis, alpha=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Patient Nodes in black and the HPO terms for each patient in different colors for a given gene diagnosis\n",
    "alpha = 0.1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    cmap=\"jet\",\n",
    "    alpha=alpha,\n",
    ")\n",
    "\n",
    "#Grab a patients HPO terms and visualize them on the scatter plot\n",
    "diagnosis_file\n",
    "gene_patients = diagnosis_file[diagnosis_file['Gene']=='CDKL5'] #This line sets the Gene name\n",
    "patients_terms = gene_patients['Terms']\n",
    "patients_nodes = gene_patients['ID']\n",
    "patients_terms = patients_terms.apply(lambda terms: [term.strip() for term in terms])\n",
    "\n",
    "for i in patients_terms.index:\n",
    "    rows_to_plot = nodes_data.loc[patients_terms[i]]\n",
    "    nodes_to_plot = nodes_data.loc[patients_nodes[i]]\n",
    "    plt.scatter(rows_to_plot['Position 1'], rows_to_plot['Position 2'], alpha = 0.7)\n",
    "    plt.scatter(nodes_to_plot['Position 1'], nodes_to_plot['Position 2'], color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Cosine distance between patients and make a matrix between each pair of patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for calculating Cosine distances\n",
    "embeddings_data = pd.DataFrame({'Node':node_ids, 'node_type':node_types,'Position':[list(position) for position in node_embeddings]})\n",
    "embeddings_data = embeddings_data[embeddings_data['node_type']=='Patient']\n",
    "embeddings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Make a matrix of each patients and their cosine distances to other patients\n",
    "embeddings_array = np.array(embeddings_data['Position'].tolist())\n",
    "\n",
    "distance_matrix = cosine_distances(embeddings_array)\n",
    "\n",
    "embeddings_matrix = pd.DataFrame(distance_matrix, index=embeddings_data['Node'], columns=embeddings_data['Node'])\n",
    "\n",
    "embeddings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings Matrix is very similar to similairty matrix so we can build the same powercurves \n",
    "#We cant use the function as is though since it sorts in ascending order and lower numbers here represent greater similairty\n",
    "\n",
    "#Function for primary level matching only\n",
    "def patient_matching_embed (diagnosis_file:pd.DataFrame, similarity_table:pd.DataFrame) -> None:\n",
    "    if not isinstance (similarity_table, pd.DataFrame) :\n",
    "        raise TypeError(\"Expected a pandas DataFrame\")\n",
    "    \n",
    "    #Since some patients have the same diagnosis, we will create two dictionaries\n",
    "    #One with patient IDs and gene diagnosis and the other with patinet ID and associated genes\n",
    "    #Keep in mind that we will have to loop in the similarity table by patient ID not number since that has been changed by the deletion of some patients \n",
    "    #with multiple diagnosed genes\n",
    "\n",
    "    #I think it will be a good idea to add an index to the similarity table \n",
    "    diagnosis_dict = diagnosis_file[['ID','Gene']].to_dict(orient='records')\n",
    "    diagnosis_dict = {item['ID'] : item['Gene'] for item in diagnosis_dict}\n",
    "\n",
    "\n",
    "    #Make a patient ID and associated gene disctionary\n",
    "    associated_genes_dict = diagnosis_file[['ID','Associated Proteins']].to_dict(orient='records')\n",
    "    associated_genes_dict = {item['ID'] : item['Associated Proteins'] for item in associated_genes_dict}\n",
    "\n",
    "    #Define a list of patients to loop through\n",
    "    patient_list = diagnosis_file['ID'].tolist()\n",
    "    #patient_list = patient_list[ : 50] #shorten list for now\n",
    "    j = 0\n",
    "    #drop patients with multiple diagnosis in the similarity table\n",
    "    #675 patients with a single gene diagnosis\n",
    "    matching_data = [] # We will do a list of tuples instead otherwise the dataframe will take ages to populate\n",
    "    k = 0 #Use k as the index in matching data\n",
    "\n",
    "  \n",
    "    for i in similarity_table.index:\n",
    "        if i not in patient_list:\n",
    "            #Drop row and coloumn of every patient id that is not in the patient list\n",
    "            similarity_table = similarity_table.drop(columns=i).drop([i])\n",
    "\n",
    "\n",
    "    match_table = similarity_table.copy()\n",
    "    match_table = match_table.astype(str)\n",
    "\n",
    "    for i in patient_list:\n",
    "        patient_diagnosis = diagnosis_dict[i] #get gene diagnosis\n",
    "        patient_interacting_genes = associated_genes_dict[i] #get associated genes\n",
    "        sim_table_subset = similarity_table[i][:] #filter out the list of patients from the similairty matrix\n",
    "        sim_table_subset = sim_table_subset.drop([i]) #drop the patinet themsevels since their value will be 1\n",
    "        sim_table_subset = sim_table_subset.sort_values(ascending=True) #put values in decending order such that 1 is higher match and 674 is lowest\n",
    "\n",
    "        patient2_list = sim_table_subset.index.tolist() #Get the IDs of other patients in decending order \n",
    "        #patient2_scores = sim_table_subset.values.tolist() #Get the scores of other patinets in decending order, we will just vaalues from sim_table_subset\n",
    "        rank = 1\n",
    "        for j in patient2_list:\n",
    "\n",
    "            patient2_id = j\n",
    "            patient2_interacting_genes = associated_genes_dict[j]\n",
    "            patient2_diagnosis = diagnosis_dict[j]\n",
    "            patient2_score = sim_table_subset[j]\n",
    "\n",
    "        \n",
    "            #We will only consider same gene and primary interactor matches for this work    \n",
    "            if patient2_diagnosis == patient_diagnosis:\n",
    "                match_table.loc[i , j] = 'same_gene'\n",
    "                gene_class = 'same_gene'\n",
    "            elif patient2_diagnosis in patient_interacting_genes:\n",
    "                match_table.loc[i , j] = 'interacting_gene'\n",
    "                gene_class = 'interacting_gene'\n",
    "            else:\n",
    "                match_table.loc[i , j] = 'no_match'\n",
    "                gene_class = 'no_match'\n",
    "            matching_data.append((i , j , patient2_score, gene_class, rank))\n",
    "            k = k + 1\n",
    "            rank = rank + 1\n",
    "\n",
    "    #Convert matching data to a dataframe\n",
    "    matching_data = pd.DataFrame(matching_data, columns=['Patient 1', 'Patient 2', 'Score', 'Match Class', 'Rank'])\n",
    "\n",
    "    #Drop the permutations of patient matches. For example UDN234 - UDN344 is the same as UDN344 and UDN234\n",
    "    matching_data['sorted'] = matching_data.apply(lambda row: tuple(sorted([row['Patient 1'], row['Patient 2']])), axis = 1)\n",
    "    # Drop duplicates based on the sorted column\n",
    "    sorted_match_data = matching_data.drop_duplicates(subset='sorted')\n",
    "    # Drop the temporary 'sorted' column\n",
    "    sorted_match_data = sorted_match_data.drop(columns='sorted')\n",
    "    return matching_data, sorted_match_data\n",
    "\n",
    "diagnosis_file = diagnosis_file.rename(columns={'Associated Genes':'Associated Proteins'})\n",
    "matching_data, sorted_match_data = patient_matching_embed(diagnosis_file, embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Cosine distanve relative to CDF\n",
    "def pheno_score_powercurve(matching_data):\n",
    "    # Group by PatientID and MatchType, get the highest rank using idxmin\n",
    "    idx = matching_data.groupby(['Patient 1', 'Match Class'])['Rank'].idxmin()\n",
    "\n",
    "    # Filter the DataFrame to get only the highest rank for each patient and match type\n",
    "    highest_rank_df = matching_data.loc[idx]\n",
    "\n",
    "    dfs_by_match_type = {}\n",
    "    for match_type in highest_rank_df['Match Class'].unique():\n",
    "        # Filter by MatchType and store in the dictionary\n",
    "        dfs_by_match_type[match_type] = highest_rank_df[highest_rank_df['Match Class'] == match_type]\n",
    "    same_gene_ranks = dfs_by_match_type['same_gene'].sort_values(by='Score',ascending=False)\n",
    "    interacting_gene_ranks = dfs_by_match_type['interacting_gene'].sort_values(by='Score',ascending=False)\n",
    "\n",
    "    interacting_gene_patients = interacting_gene_ranks[~interacting_gene_ranks['Patient 1'].isin(same_gene_ranks['Patient 1'])]\n",
    "\n",
    "    interacting_gene_patients['Match Class'] = 'interating_gene_only'\n",
    "\n",
    "    #Concatenate Dataframes:\n",
    "    combined_ranks = pd.concat([same_gene_ranks,interacting_gene_ranks])\n",
    "    combined_ranks = combined_ranks.sort_values(['Match Class', 'Score'],ascending=False)\n",
    "\n",
    "    # Step 4: Compute the cumulative proportion (CDF) for each group\n",
    "    combined_ranks['CDF'] =combined_ranks.groupby('Match Class')['Score'].rank(method='max', pct=True)\n",
    "\n",
    "\n",
    "    # Step 3: Create the CDF plot using Altair\n",
    "    cdf_plot = alt.Chart(combined_ranks).mark_line().encode(\n",
    "        x=alt.X('Score:Q', scale=alt.Scale(reverse=False),axis=alt.Axis(title='Cosine Distance')),    \n",
    "        y=alt.Y('CDF:Q'),\n",
    "        color='Match Class:N'  # Use 'Group' to differentiate the lines\n",
    "    ).properties(\n",
    "        title='Cumulative Distribution Function (CDF) by Group',\n",
    "        width=500,\n",
    "        height=300\n",
    "    )\n",
    "    return cdf_plot\n",
    "\n",
    "cdf_plot = pheno_score_powercurve(matching_data)\n",
    "cdf_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_powercurve (matching_data, graph_color):\n",
    "    #Plot the cosine matched patients based on Rank \n",
    "    # Group by PatientID and MatchType, get the highest rank using idxmin\n",
    "    idx = matching_data.groupby(['Patient 1', 'Match Class'])['Rank'].idxmin()\n",
    "\n",
    "    # Filter the DataFrame to get only the highest rank for each patient and match type\n",
    "    highest_rank_df = matching_data.loc[idx]\n",
    "\n",
    "    dfs_by_match_type = {}\n",
    "    for match_type in highest_rank_df['Match Class'].unique():\n",
    "        # Filter by MatchType and store in the dictionary\n",
    "        dfs_by_match_type[match_type] = highest_rank_df[highest_rank_df['Match Class'] == match_type]\n",
    "    same_gene_ranks = dfs_by_match_type['same_gene'].sort_values(by='Score',ascending=False)\n",
    "    interacting_gene_ranks = dfs_by_match_type['interacting_gene'].sort_values(by='Score',ascending=False)\n",
    "\n",
    "    #Concatenate Dataframes:\n",
    "    combined_ranks = pd.concat([same_gene_ranks])\n",
    "    combined_ranks = combined_ranks.sort_values(['Match Class', 'Score'],ascending=False)\n",
    "\n",
    "    # Step 4: Compute the cumulative proportion (CDF) for each group\n",
    "    combined_ranks['CDF'] =combined_ranks.groupby('Match Class')['Rank'].rank(method='max', pct=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Step 3: Create the CDF plot using Altair\n",
    "    cdf_plot = alt.Chart(combined_ranks).mark_line().encode(\n",
    "        x=alt.X('Rank:Q', scale=alt.Scale(reverse=False),axis=alt.Axis(title='Rank')),    \n",
    "        y=alt.Y('CDF:Q'),\n",
    "        color = alt.ColorValue(graph_color),\n",
    "    ).properties(\n",
    "        title='Cumulative Distribution Function (CDF) by Group',\n",
    "        width=500,\n",
    "        height=300\n",
    "    )\n",
    "    return cdf_plot\n",
    "\n",
    "cdf_plot = rank_powercurve(matching_data, 'purple')\n",
    "cdf_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we need to compare cosine matching to phenotype based matching\n",
    "\n",
    "#Perform patient matching based on the similarity matrix based on phenotype score \n",
    "matching_data_by_phenotype, _, _ = patient_matching.patient_matching(diagnosis_file, similarity_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_plot_2 = rank_powercurve(matching_data_by_phenotype, 'blue')\n",
    "cdf_plot_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_plot_3 = alt.layer(cdf_plot + cdf_plot_2)\n",
    "cdf_plot_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Weird cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try matching with the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block bugs out\n",
    "patient_data = pd.read_csv('./data_files/753_UDNDx_Patients_8.26.24.csv') #reimport patient data\n",
    "\n",
    "patient_data = patient_data.rename(columns={'Genes' : \"Gene\"})\n",
    "filtered_patient_data = pd.merge(patient_data, association_data, on='Gene', how='left')\n",
    "filtered_patient_data=filtered_patient_data['Associated Genes'].fillna('')\n",
    "\n",
    "diagnosis_file = filtered_patient_data #The rest of the script uses diagnosis file \n",
    "#HPO terms are saved as a string, convert to a list\n",
    "#['Terms'] = diagnosis_file['Terms'].apply(lambda x: x.split(';'))\n",
    "\n",
    "\n",
    "#Drop patients from the similairty table that we are not looking at in the diagnosis file\n",
    "for i in similarity_table.index:\n",
    "    if i not in patient_list:\n",
    "        similarity_table = similarity_table.drop(columns=i).drop([i])\n",
    "\n",
    "phenotypic_similarity = similarity_table\n",
    "phenotypic_similarity.index.name = 'ID'\n",
    "\n",
    "\n",
    "#We need a matrix wherein we have patient ID in one coloumn and a matrix of genes that are associated with the patient\n",
    "#Remove confidence scores in associated genes coloumn\n",
    "diagnosis_file['Associated Genes'] = diagnosis_file['Associated Genes'].apply(\n",
    "    lambda lst: [tup[0] for tup in lst] if isinstance(lst, list) and len(lst) > 0 else lst\n",
    ")\n",
    "\n",
    "\n",
    "diagnosis_file = diagnosis_file.rename(columns={'Associated Genes':'Associated Proteins'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform phenotype based matching\n",
    "matching_data_by_phenotype, _, _ = patient_matching.patient_matching(diagnosis_file, similarity_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_data, sorted_match_data = patient_matching_embed(diagnosis_file, embeddings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_plot = rank_powercurve(matching_data, 'purple')\n",
    "cdf_plot_2 = rank_powercurve(matching_data_by_phenotype, 'blue')\n",
    "cdf_plot_3 = alt.layer(cdf_plot + cdf_plot_2)\n",
    "cdf_plot_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_csv('753_UDNDx_Patients_8.26.24.csv') #reimport patient data\n",
    "\n",
    "\n",
    "patient_data = patient_data.rename(columns={'Genes' : \"Gene\"})\n",
    "filtered_patient_data = pd.merge(patient_data, association_data, on='Gene', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_patient_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
